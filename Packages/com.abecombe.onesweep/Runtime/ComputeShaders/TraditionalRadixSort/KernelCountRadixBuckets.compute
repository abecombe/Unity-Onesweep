#pragma kernel CountRadixBuckets

#pragma multi_compile KEY_TYPE_UINT KEY_TYPE_INT KEY_TYPE_FLOAT
#pragma multi_compile SORTING_ORDER_ASCENDING SORTING_ORDER_DESCENDING
#pragma multi_compile USE_DIRECT_DISPATCH USE_INDIRECT_DISPATCH

#include "../RadixCommon/Radix.hlsl"
#include "../RadixCommon/DispatchUtils.hlsl"

#define THREADS_PER_GROUP (128u)
#define ITEMS_PER_GROUP (RADIX_BASE * 15u) // should be equal to ITEMS_PER_GROUP of KernelSort.compute

RWStructuredBuffer<uint> bucket_count_buffer; // size: RADIX_BASE * group_count
StructuredBuffer<DATA_TYPE> key_in_buffer; // size: sort_item_count

uint current_pass_radix_shift;

#define GROUP_SHARED_SIZE (RADIX_BASE * 2u)
groupshared uint group_shared[GROUP_SHARED_SIZE];

/**
 * \brief Counts the number of elements for each bucket in a single radix sort pass.
 *
 * \note dispatch group size: ceil(sort_item_count / ITEMS_PER_GROUP)
 *
 * This kernel performs the histogram calculation (counting) phase of the radix sort.
 * Each thread group processes a chunk of the input key array, `key_in_buffer`.
 * Threads within a group extract a radix digit from their assigned keys based on the
 * current pass shift (`current_pass_radix_shift`) and increment a bucket counter.
 *
 * The aggregation is performed atomically using InterlockedAdd on `group_shared` memory,
 * which is split into two halves to reduce bank conflicts and contention.
 *
 * Finally, each group writes its computed bucket counts to the `bucket_count_buffer`.
 * This buffer will be used as input for the next scan (prefix sum) operation.
 */
[numthreads(THREADS_PER_GROUP, 1, 1)]
void CountRadixBuckets(uint group_thread_id : SV_GroupThreadID, uint group_id : SV_GroupID)
{
#if defined(USE_INDIRECT_DISPATCH)
    const uint sort_count = get_sort_count();
#endif

    [unroll(GROUP_SHARED_SIZE / THREADS_PER_GROUP)]
    for (uint i = group_thread_id; i < GROUP_SHARED_SIZE; i += THREADS_PER_GROUP)
        group_shared[i] = 0u;

    GroupMemoryBarrierWithGroupSync();

    const uint group_shared_offset = (group_thread_id >> 6u) * RADIX_BASE; // 0, 0, ... , 0, 256, 256, ... , 256
    const uint group_item_end = min(sort_count, (group_id + 1u) * ITEMS_PER_GROUP);

    for (uint j = group_thread_id + group_id * ITEMS_PER_GROUP; j < group_item_end; j += THREADS_PER_GROUP)
    {
        InterlockedAdd(group_shared[get_radix_digit(from_original_key_to_sorting_key(key_in_buffer[j]), current_pass_radix_shift) + group_shared_offset], 1u);
    }

    GroupMemoryBarrierWithGroupSync();

    [unroll(RADIX_BASE / THREADS_PER_GROUP)]
    for (uint k = group_thread_id; k < RADIX_BASE; k += THREADS_PER_GROUP)
    {
        bucket_count_buffer[group_id * RADIX_BASE + k] = group_shared[k] + group_shared[k + RADIX_BASE];
    }
}